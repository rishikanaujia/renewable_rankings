# Renewable Rankings - Environment Configuration
# Copy this file to .env and adjust values as needed

# ======================
# SERVICE MODE
# ======================
# Switch between mock data (fast) and real AI agents (slower, production)
# Values: "true" or "false"
# Default: "false" (uses mock service with sample data)
USE_REAL_AGENTS=false

# ======================
# GRADIO UI SETTINGS
# ======================
# Server configuration
GRADIO_SERVER_NAME=0.0.0.0
GRADIO_SERVER_PORT=7860
GRADIO_SHARE=false

# ======================
# LOGGING
# ======================
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO
LOG_FILE=logs/app.log

# ======================
# DEBUG MODE
# ======================
# Enable debug mode for development
DEBUG=false

# ======================
# AI/LLM SETTINGS (for AI_POWERED mode)
# ======================
# Required when agents run in AI_POWERED mode for document extraction

# LLM Provider (optional - defaults to config/llm_config.yaml)
# LLM_PROVIDER=anthropic
# LLM_MODEL=claude-3-5-sonnet-20241022

# Anthropic Claude API (recommended for extraction)
# Get key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# Alternative: OpenAI API
# Get key from: https://platform.openai.com/api-keys
# OPENAI_API_KEY=your-openai-api-key-here

# Alternative: Azure OpenAI
# AZURE_OPENAI_API_KEY=your-api-key-here
# AZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com/
# AZURE_OPENAI_DEPLOYMENT=your-deployment-name
# AZURE_OPENAI_API_VERSION=2024-02-01

# NOTE: Set ANTHROPIC_API_KEY in .env, NOT in llm_config.yaml
# The config file contains model settings, not credentials
