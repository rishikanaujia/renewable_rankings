# AI Extraction System - Environment Configuration Template
# Copy this file to .env and fill in your API keys

# ============================================================================
# LLM API Keys
# ============================================================================

# Anthropic Claude API Key (recommended for high-quality extraction)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# OpenAI API Key (optional - for GPT-4, GPT-3.5)
OPENAI_API_KEY=your_openai_api_key_here

# Azure OpenAI Configuration (optional)
AZURE_OPENAI_KEY=your_azure_openai_key_here
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_VERSION=2023-05-15

# ============================================================================
# LLM Configuration
# ============================================================================

# Default LLM provider (options: anthropic, openai, azure_openai)
LLM_PROVIDER=anthropic

# Default model name
LLM_MODEL_NAME=claude-3-sonnet-20240229

# Temperature (0.0 = deterministic, 1.0 = creative)
LLM_TEMPERATURE=0.1

# Max tokens in response
LLM_MAX_TOKENS=2000

# ============================================================================
# Cache Configuration
# ============================================================================

# Enable caching (true/false)
CACHE_ENABLED=true

# Cache directory (for file-based cache)
CACHE_DIR=./extraction_cache

# Cache TTL in seconds (86400 = 24 hours)
CACHE_TTL=86400

# Redis configuration (optional - for distributed cache)
# REDIS_HOST=localhost
# REDIS_PORT=6379
# REDIS_DB=0
# REDIS_PASSWORD=

# ============================================================================
# Rate Limiting
# ============================================================================

# Maximum requests per minute
MAX_REQUESTS_PER_MINUTE=60

# Maximum tokens per minute
MAX_TOKENS_PER_MINUTE=90000

# ============================================================================
# Logging
# ============================================================================

# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Log file path (optional)
# LOG_FILE=./logs/extraction.log

# ============================================================================
# Document Processing
# ============================================================================

# Chunk size for text splitting
CHUNK_SIZE=4000

# Chunk overlap for text splitting
CHUNK_OVERLAP=200

# Enable table extraction from PDFs
EXTRACT_TABLES=true

# ============================================================================
# Extraction Configuration
# ============================================================================

# Maximum retries for failed extractions
MAX_RETRIES=3

# Retry delay in seconds
RETRY_DELAY=1.0

# Minimum confidence threshold
MIN_CONFIDENCE=0.0

# ============================================================================
# Development/Testing
# ============================================================================

# Enable debug mode
DEBUG=false

# Use mock data instead of real API calls (for testing)
USE_MOCK_DATA=false
